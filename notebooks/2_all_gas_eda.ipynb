{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27b0b00-b046-43be-be43-63d8cf67a825",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Greenhouse Gases  \n",
    "**Data Source**: Processed NOAA data (cleaned in `1_data_loading.ipynb`)  \n",
    "\n",
    "## Key Notes  \n",
    "- **Focus Gas**: CH₄ (Methane) - primary analysis target  \n",
    "- **Data Quality**:  \n",
    "  - Missing values: All rows kept (missing values → `NaN`)  \n",
    "  - Negative values: Converted to `NaN` (non-physical concentrations)  \n",
    "  - Data start dates: Gases have distinct collection start dates  \n",
    "- Raw data pipeline documented in [`1_data_loading.ipynb`](../notebooks/1_data_loading.ipynb)  \n",
    "\n",
    "## Data Files  \n",
    "- **Input**: `../data/processed/all_ghg_aligned.csv`  \n",
    "- **Output**: `../data/processed/all_ghg_aligned_nan.csv`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941da02-d2b1-4ea5-bbb9-bf0b798ee130",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8574bbce-9156-41d6-9eed-adeeb77e4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "from pathlib import Path\n",
    "import os\n",
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74297eaa-02bd-4b97-965a-4e2f6d3c8af3",
   "metadata": {},
   "source": [
    "# Make Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc67931c-132f-4975-afb1-d884596055ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic path handling\n",
    "NOTEBOOK_PATH = Path.cwd() # gets current working directory\n",
    "if 'notebooks' in str(NOTEBOOK_PATH): # if running from /notebooks/\n",
    "    PROCESSED_DATA = NOTEBOOK_PATH.parent / 'data' / 'processed'\n",
    "else: # if running from the repo root\n",
    "    PROCESSED_DATA = NOTEBOOK_PATH / 'data' / 'processed'\n",
    "\n",
    "# create folder (if necessary)\n",
    "PROCESSED_DATA.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2a7097-2fd5-4bd8-98eb-4c45fba70bf0",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b967b1-274e-4e50-aa52-e030c8c94674",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/all_ghg_aligned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/processed/all_ghg_aligned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NewEnv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NewEnv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NewEnv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NewEnv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NewEnv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/all_ghg_aligned.csv'"
     ]
    }
   ],
   "source": [
    "df_combined = pd.read_csv(\"../data/processed/all_ghg_aligned.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb8733-9c66-4814-b7ef-8f7d64e004fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c96c59-939f-4f31-ab44-171785214324",
   "metadata": {},
   "source": [
    "# EDA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a90de-f9c6-493a-ab0d-2ee161a53fba",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db95a5b-6d80-4434-8556-19532d0652a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81ce8b-1b03-4eb7-b8dd-d1f3174d2e71",
   "metadata": {},
   "source": [
    "## Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac239e-98c2-467c-b82b-29b0824357b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a6d98a-1b17-401d-8bad-c340203f6824",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494ef0f-323e-42a9-92ab-f596e5f1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two classes of null values to be concerned with:\n",
    "# - null values at the beginning of a series are likely due to the different data collection start dates for each gas type\n",
    "# - internal null values are null/missing values after the data collection start date for the particular gas.  These null values \n",
    "# likely need to be imputed.  \n",
    "\n",
    "df_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3d2f06-2d68-4986-afc5-8268fb9a4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fill values for 'values' is -999.999.  This is essentially the same as a null value.  \n",
    "# So, I will check on the number of fill values.  \n",
    "\n",
    "fillvalue_counts = (df_combined == -999.999).sum()\n",
    "fillvalue_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e00b7ba-bb17-42eb-ad61-bb20384539e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize location of null values for each feature\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "sns.heatmap(df_combined.isnull(), cmap='Paired', cbar=False, yticklabels=False)\n",
    "plt.title('Missing Data Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44896607-3da9-491e-9b65-b00f4daab56a",
   "metadata": {},
   "source": [
    "Null (NaN) values are data points that were not collected or recorded. Many null values occur at the beginning of the timeseries for each gas, except CO2, since measurement of the other gases began after the first CO2 measurement. \n",
    "\n",
    "measurement start dates:\n",
    "- CO2: 1969-8-20\n",
    "- CH4: 1983-5-6\n",
    "- CO: 1989-7-7\n",
    "- N2O: 1995-12-15\n",
    "- SF6: 1995-12-15\n",
    "\n",
    "I will not impute any null value that exist at dates earlier than the first measurement date for each gas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ef00f-b7e5-4ed5-9044-a0e32de1a0c6",
   "metadata": {},
   "source": [
    "## Negative Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620de706-136d-4201-8d45-254de7696061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some negative values for gas concentration.  This doesn't make physical sense. \n",
    "# One possible explanation is that the GC sensor was zeroed incorrectly. Either way, I will \n",
    "# likely set them to NaN.  First, inspect:\n",
    "\n",
    "neg_value_count = (df_combined.iloc[:,1:] < 0).sum()\n",
    "print('----- Negative Value Count per Gas Type -----')\n",
    "print(neg_value_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66a84e-bbbf-4168-a9e1-239ada0d2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the location of the negative values\n",
    "\n",
    "plt.figure(figsize=(6,8))\n",
    "sns.heatmap(df_combined.iloc[:,1:] < 0, cmap='Paired', cbar=False, yticklabels=False)\n",
    "plt.title('Negative Value Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cef414-e63a-4190-b126-1c1746179a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace negative values with NaN\n",
    "\n",
    "df_combined.iloc[:,1:] = df_combined.iloc[:,1:].mask(df_combined.iloc[:,1:] < 0, np.nan)\n",
    "                          \n",
    "new_neg_count = (df_combined.iloc[:,1:] < 0).sum()\n",
    "print('----- Remaininig Negative Values per Gas Type -----')\n",
    "print(new_neg_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb017dec-895c-4086-9db3-1efc7bf75dd8",
   "metadata": {},
   "source": [
    "All NaN values that originate after the data collection start date will be imputed during preprocessing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5504c-1cb3-4d7d-abc7-0a13c59a83a5",
   "metadata": {},
   "source": [
    "## Store New Dateframe as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23fcae-bc83-4810-b503-106616599d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed data to the processed data folder\n",
    "\n",
    "print(f'Processed data will save to: {PROCESSED_DATA}')\n",
    "df_combined.to_csv(PROCESSED_DATA / 'all_ghg_aligned_nan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9c0b3-abde-4fd5-9d63-34daa2a25c6d",
   "metadata": {},
   "source": [
    "## Analyze Long-Term Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2472ff-61bc-4158-b887-934d8f16bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the yearly average concentration values vs time to visualize the full trend of \n",
    "# atmospheric concentrations over time. \n",
    "\n",
    "# calculate yearly averages for each gas\n",
    "df_combined['year'] = df_combined['date'].dt.year\n",
    "yearly_avg_df = df_combined.groupby('year').mean(numeric_only=True)\n",
    "\n",
    "unit_map = {\n",
    "    'CH4' : 'ppb',\n",
    "    'CO' : 'ppb',\n",
    "    'CO2' : 'ppm',\n",
    "    'H2' : 'ppb',\n",
    "    'N2O' : 'ppb',\n",
    "    'SF6' : 'ppt'\n",
    "}\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(12,6))\n",
    "for gas in ['CH4','CO','CO2','H2','N2O','SF6']:\n",
    "    label = f'{gas} ({unit_map[gas]})'\n",
    "    plt.plot(yearly_avg_df.index, yearly_avg_df[gas], label=label, linewidth=2)\n",
    "\n",
    "plt.title('Annual Mean Atmospheric GHG Concentrations', fontsize=18)\n",
    "plt.ylabel('Concentration', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb6063-de8c-41f6-9982-9a2ba2b8e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data table of the linear regression metrics\n",
    "\n",
    "gas_trend_data = []\n",
    "\n",
    "gases = {\n",
    "    'CH4': {'unit': 'ppb', 'scale':1},\n",
    "    'CO': {'unit': 'ppb', 'scale':1},\n",
    "    'CO2': {'unit': 'ppm', 'scale':1},\n",
    "    'H2': {'unit': 'ppb', 'scale':1},\n",
    "    'N2O': {'unit': 'ppb', 'scale':1},\n",
    "    'SF6': {'unit': 'ppt', 'scale':1}\n",
    "}\n",
    "\n",
    "for gas in gases.keys():\n",
    "    valid_data = yearly_avg_df[gas].dropna()\n",
    "    x = valid_data.index\n",
    "    y = valid_data.values\n",
    "\n",
    "    # linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x,y)\n",
    "\n",
    "    # calculate 95% confidence interval for the slope\n",
    "    ci_low = slope - (1.96 * std_err)\n",
    "    ci_high = slope + (1.96 * std_err)\n",
    "    \n",
    "    gas_trend_data.append({\n",
    "        'Gas' : gas,\n",
    "        'Slope' : f'{slope:.3f}',\n",
    "        'Unit' : f'{gases[gas]['unit']}/yr',\n",
    "        'R-sqrd' : f'{r_value**2:.3f}',\n",
    "        'Std Err' : f'{std_err:.3f}',\n",
    "        'p-val' : f'{p_value:.2e}',\n",
    "        '95% CI Low' : f'{ci_low:.3f}',\n",
    "        '95% CI high' : f'{ci_high:.3f}',\n",
    "        'Start Yr' : x.min(),\n",
    "        'End yr' : x.max()\n",
    "    })\n",
    "\n",
    "gas_trend_df = pd.DataFrame(gas_trend_data)\n",
    "print(gas_trend_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6712edc5-22f8-4b9c-ac0a-a577b26b8e05",
   "metadata": {},
   "source": [
    "All gases except CO show a statistically significant annual mean increase in atmospheric concentration.  CO2 has the greatest mean increase of 1.91 ppm/year, followed by CH4 at 6.7 ppb/year.  The data also corroborate a decrease in atmospheric CO concentrations due to cleaner combustion technologies and reduced emissions (https://earthobservatory.nasa.gov/images/149876/a-global-decline-in-carbon-monoxide).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a11d8-10cd-4ad3-a65e-1021e1c46eea",
   "metadata": {},
   "source": [
    "## Visualize Full Data Series and Run Stationarity Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f035a1e-8a30-4932-825a-4545fce06d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ADF and KPSS tests to determine if statistical properties, including mean, variance, and autocorrelation, \n",
    "# are stable (stationary) over time.  \n",
    "# ADF - Augmented Dickey-Fuller test\n",
    "# KPSS - Kwiatkowski-Phillips-Schmidt-Shin test\n",
    "\n",
    "gas_columns = ['CH4','CO','CO2','H2','N2O','SF6']\n",
    "\n",
    "# function to check stationarity\n",
    "def check_stationarity(series, gas):\n",
    "    adf_result = adfuller(series.dropna())\n",
    "    kpss_result = kpss(series.dropna(), regression='c')\n",
    "\n",
    "    print(f'ADF and KPSS tests for {gas}:')\n",
    "    print(f'ADF statistic {adf_result[0]:.4f}')\n",
    "    print(f'ADF p-value {adf_result[1]:.4f}')\n",
    "    print(f'ADF critical values: {adf_result[4]}\\n')\n",
    "    \n",
    "    print(f'KPSS statistic {kpss_result[0]:.4f}')\n",
    "    print(f'KPSS p-value {kpss_result[1]:.4f}')\n",
    "    print(f'KPSS critical values: {kpss_result[3]}\\n')\n",
    "\n",
    "    if adf_result[1] < 0.05 and kpss_result[1] > 0.05:\n",
    "        print(f'the {gas} time series is likely stationary according to ADF and KPSS tests.\\n')\n",
    "    elif adf_result[1] > 0.05 and kpss_result[1] < 0.05:\n",
    "        print(f'the {gas} time series is non-stationary according to ADF and KPSS tests.\\n')\n",
    "    elif adf_result[1] > 0.05 and kpss_result[1] > 0.05:\n",
    "        print(f'the {gas} time series may be trend-stationary according to ADF and KPSS tests.\\n')\n",
    "    else: \n",
    "        print(f'the {gas} time series may be difference-stationary according to ADF and KPSS tests.\\n')\n",
    "\n",
    "# plot raw data and perform the ADF test\n",
    "for gas in gas_columns:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df_combined[gas], label=gas)\n",
    "    plt.title(f'{gas} Time Series', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    check_stationarity(df_combined[gas], gas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4b449-c808-402b-907f-237e9f8cda46",
   "metadata": {},
   "source": [
    "The ADF and KPSS values strongly indicate non-stationarity for CH4, CO2, N2O, and SF6, which isn't surprsing considering the substantial upward trajectory of the gas concentrations over time observed in the long-term trend analysis as well as what is well known about the accumulation of these gases in the atmosphere. Furthermore, all raw data plots suggest seasonality, which is also a known quality of GHG concentration data.  Seasonality will present autocorrelation, which also leads to non-stationarity.  These datasets will need to be differenced to remove the upward trend and to stabilize the mean for fitting a SARIMA model.  \n",
    "\n",
    "All data series, with the possible exception of CO, have significant spikes, which may be outliers. STL (seasonal trend decomposition with LOESS) will be used to detect and handle outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36882024-4c8c-4694-99fd-91ad7f7c2630",
   "metadata": {},
   "source": [
    "## Data Frequency (per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b435e37-50fb-4b60-8725-b931741c8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize seasonal cycles in a snippet of the full dataset.  \n",
    "# I will use [CH4] values between the years of 2013 - 2018 to avoid spikes.  \n",
    "\n",
    "mask = (df_combined['date'] >= '2013-01-01') & (df_combined['date'] <= '2018-01-01')\n",
    "ch4_subset = df_combined.loc[mask, 'CH4']\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df_combined.loc[mask, 'date'], ch4_subset, linewidth=1.5)\n",
    "plt.title('Atmospheric CH4 Concentration - Five Year Window', fontsize = 18)\n",
    "plt.ylabel('Concentration (PPB)', fontsize=18)\n",
    "plt.xlabel('Year', fontsize=18)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b0424-6567-46ea-837e-a064d1f1c440",
   "metadata": {},
   "source": [
    "The yearly seasonality is apparent in all gas dataset plots and highlighted here for a subset of CH4 data as an example.  The increasing trend can also be observed in this 5 year window.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742bf59-8c84-4910-9d15-da2ec90a290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The seasonality appears as a single cycle per year for each gas. \n",
    "# Confirm the number of datapoints per year for each gas.\n",
    "\n",
    "df_counts = df_combined.copy()\n",
    "\n",
    "df_counts['year'] = df_counts['date'].dt.year # extract the year\n",
    "yearly_counts = df_counts.groupby('year').count()\n",
    "yearly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0857b4-167f-465f-a5b5-e73dfc930096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# As expected, there is variation in the number of data points per year.  \n",
    "# I will determine and use the mode of each gas for signal decomposition, preprocessing, and modeling.\n",
    "\n",
    "seasonal_mode = yearly_counts.replace(0, np.nan).mode().iloc[0] \n",
    "seasonal_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118e613-4b94-4402-89d1-01412ed0b740",
   "metadata": {},
   "source": [
    "The yearly mode for each data series is 52, which means that the data is generally collected weekly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54570b1-ff66-4334-8ada-4775468b7640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
