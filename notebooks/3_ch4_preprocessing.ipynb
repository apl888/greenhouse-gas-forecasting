{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222d60ef-00f5-4fbf-968a-a4477eee91d3",
   "metadata": {},
   "source": [
    "# CH4 Time Series Preprocessing and EDA\n",
    "**Purpose**: Prepare methane (CH4) data for forecasting using `GasPreprocessor`  \n",
    "\n",
    "## Workflow  \n",
    "1. Load cleaned GHG data  \n",
    "2. Initialize preprocessor  \n",
    "3. Fit/transform CH4 series  \n",
    "4. Save processed data  \n",
    "\n",
    "**Input**: `data/processed/all_ghg_aligned_nan.csv`  \n",
    "**Output**: `data/processed/ch4_preprocessed.csv`  \n",
    "\n",
    "[View GasPreprocessor docs](../src/preprocessing.py)  \n",
    "\n",
    "**Note**: The identical preprocessing will be reapplied to the training set in `4_ch4_modeling.ipynb`  \n",
    "to avoid data leakage. This full-dataset version is for exploratory purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e63c49a-8ed1-4c01-a6ff-44f6d84152f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable auto-reloading of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# ensure src/imports work\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e60c5e-92ec-4d5d-b4d0-d260df675c5e",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4679fde7-35ae-4f83-8e57-1ae2d7baf391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GasPreprocessor imported sucessfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.preprocessing import GasPreprocessor\n",
    "print('GasPreprocessor imported sucessfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db5e89-4298-4d72-a685-48fbb45c07b4",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f66eab9-ff1a-4e99-8461-a8f1629fe38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 2562 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>CO2</th>\n",
       "      <th>H2</th>\n",
       "      <th>N2O</th>\n",
       "      <th>SF6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1969-08-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1969-08-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1969-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1969-09-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1969-09-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  CH4  CO      CO2  H2  N2O  SF6\n",
       "0 1969-08-20  NaN NaN      NaN NaN  NaN  NaN\n",
       "1 1969-08-27  NaN NaN      NaN NaN  NaN  NaN\n",
       "2 1969-09-02  NaN NaN      NaN NaN  NaN  NaN\n",
       "3 1969-09-12  NaN NaN  320.945 NaN  NaN  NaN\n",
       "4 1969-09-24  NaN NaN  320.890 NaN  NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load cleaned data (with negative values --> NaN)\n",
    "df = pd.read_csv(\n",
    "    '../data/processed/all_ghg_aligned_nan.csv',\n",
    "    parse_dates=['date'],\n",
    "    dtype={'CH4': float}\n",
    ")\n",
    "\n",
    "print(f'loaded {len(df)} records')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c156c7cb-d9da-46de-8a1e-71e260a5a790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (2562, 2)\n",
      "NaN values in CH4: 440\n",
      "Negative values in CH4: 0\n",
      "Date range: 1969-08-20 00:00:00 to 2025-04-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check input data before calling fit_transform\n",
    "print(f\"Input data shape: {df[['date', 'CH4']].shape}\")\n",
    "print(f\"NaN values in CH4: {df['CH4'].isna().sum()}\")\n",
    "print(f\"Negative values in CH4: {(df['CH4'] < 0).sum()}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81706c3a-4505-4714-8dbf-d58d07ce8bea",
   "metadata": {},
   "source": [
    "# Initialize Preprocessor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce459b4-2007-4465-a629-94e728e5b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure for weekly CH4 data with yearly seasonality\n",
    "preprocessor = GasPreprocessor(\n",
    "    gas_name='CH4',\n",
    "    do_eda=True,\n",
    "    iqr_factor=3.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9240c086-f96e-4ebd-a1a5-d93df8d2bd8e",
   "metadata": {},
   "source": [
    "## CH4 Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f70638b-93f0-42bb-af5b-75e433b4f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Fitting preprocessing for CH4\n",
      "Trimming 388 leading NaN values\n",
      "Trimming 8 trailing NaN values\n",
      "Raw data: 2562 points, 440 NaNs\n",
      "Trimmed data: 2166 points, 44 NaNs\n",
      "Data range after trimming: 1983-05-06 00:00:00 to 2024-12-31 00:00:00\n",
      "After resampling: 2175 points, 78 NaNs\n",
      "[INFO] Found 42 potential outliers using robust STL residuals.\n",
      "After outlier removal: 2175 points, 120 NaNs\n",
      "After smoothing: 2175 points, 0 NaNs\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'Timestamp' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run full preprocessing pipeline\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ch4_preprocessed \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(\n\u001b[0;32m      3\u001b[0m     df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH4\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m      4\u001b[0m     custom_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH4 Time Series: Raw Data vs Smoothed, Resampled, & Interpolated\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Show results\u001b[39;00m\n\u001b[0;32m      8\u001b[0m display(ch4_preprocessed\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\greenhouse-gas-forecasting\\notebooks\\..\\src\\preprocessing.py:237\u001b[0m, in \u001b[0;36mGasPreprocessor.fit_transform\u001b[1;34m(self, df, custom_title)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, df, custom_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m    Fits the preprocessor on the input DataFrame and returns the transformed series.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    pd.Series: Transformed gas time series.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(df, custom_title\u001b[38;5;241m=\u001b[39mcustom_title)  \n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(df, custom_title\u001b[38;5;241m=\u001b[39mcustom_title)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\greenhouse-gas-forecasting\\notebooks\\..\\src\\preprocessing.py:149\u001b[0m, in \u001b[0;36mGasPreprocessor.fit\u001b[1;34m(self, df, custom_title)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# debug after smoothing\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter smoothing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(smoothed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m points, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msmoothed\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m NaNs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m interpolated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpolate_series(smoothed)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# debug after interpolation\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter interpolation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(interpolated)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m points, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterpolated\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m NaNs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\greenhouse-gas-forecasting\\notebooks\\..\\src\\preprocessing.py:352\u001b[0m, in \u001b[0;36mGasPreprocessor._interpolate_series\u001b[1;34m(self, series)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_interpolate_series\u001b[39m(\u001b[38;5;28mself\u001b[39m, series):\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;66;03m# Ensure we're not trying to interpolate before the first valid date\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m series\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_date_:\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Series contains dates before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_date_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Trimming to valid range.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    354\u001b[0m         series \u001b[38;5;241m=\u001b[39m series\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_date_:]\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'Timestamp' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Run full preprocessing pipeline\n",
    "ch4_preprocessed = preprocessor.fit_transform(\n",
    "    df[['date', 'CH4']],\n",
    "    custom_title='CH4 Time Series: Raw Data vs Smoothed, Resampled, & Interpolated'\n",
    ")\n",
    "\n",
    "# Show results\n",
    "display(ch4_preprocessed.head())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab81a5-fdef-466b-a272-ac697bdf8602",
   "metadata": {},
   "source": [
    "## CH4 Preprocessing Results Summary\n",
    "\n",
    "### **Preprocessing**\n",
    "The preprocessing pipeline successfully handled outliers and missing (NaN) values while remaining consistent with the original time series characteristics.  \n",
    "\n",
    "### **Stationarity Analysis**\n",
    "All processing stages (raw --> smoothed --> resampled) show consistent non-stationarity:\n",
    "- **ADF Test**: Fails to reject H0 (p > 0.05)  \n",
    "- **KPSS Test**: Rejects H0 (p < 0.05)  \n",
    "*Interpretation*: Strong trend dominance persists through preprocessing, which is expected and appropriate.  Differencing to achieve stationarity will be handled during SARIMA model specification.  \n",
    "\n",
    "### **STL Decomposition Insights**\n",
    "Analysis of the STL decomposition residuals indicates homoscedastic variance:\n",
    "- **Breusch-Pagan test**: No heteroscedasticity detected (p = 0.72)\n",
    "- **White test**: No heteroscedasticity detected (p = 0.64)\n",
    "  \n",
    "Constant variance in residuals is an optimal characteristic for SARIMA modeling.  \n",
    "  \n",
    "### **Autocorrelation Diagnostics**\n",
    "- **ACF of Residuals**:  \n",
    "  - Slow decay in ACF suggests an autoregressive (AR) component \n",
    "  - Significant lags at 1-5, potentially indicating an MA(5) process (MA = moving average)  \n",
    "  - Spike at lag 52 suggests residual seasonality that may require seasonal AR or MA terms\n",
    "- **PACF of Residuals**:  \n",
    "  - Sharp cutoff after lag 1 suggests a strong AR(1) process \n",
    "\n",
    "### **Key Implications for Modeling**\n",
    "1. Required transformations:  \n",
    "   - **Differencing**: First order differencing will be necessary to address persistent (upward) trend\n",
    "   - **Seasonal adjustment**: Seasonal terms (likely period 52) should be incorporated to capture remaining seasonal pattern\n",
    "2. Initial model specification:  \n",
    "   - ARIMA(1,1,5) as starting point  \n",
    "   - Seasonal periodicity: 52 weeks  \n",
    "3. Variance stability:\n",
    "   - The homoscedastic residuals suggest that variance-stabilizing transformations may not be necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fbf0c-4e20-4161-9aa1-ec8ee814394c",
   "metadata": {},
   "source": [
    "# Save Preprocessed CH4 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc718186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH4 preprocessed data saved to:\n",
      "..\\data\\processed\\ch4_preprocessed.csv\n",
      "Shape: (2187,)\n",
      "Last 5 records:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-03-02    1977.445\n",
       "2025-03-09    1977.445\n",
       "2025-03-16    1977.445\n",
       "2025-03-23    1977.445\n",
       "2025-03-30    1977.445\n",
       "Freq: W-SUN, Name: CH4, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# define output path\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# save metadata\n",
    "output_path = output_dir / 'ch4_preprocessed.csv'\n",
    "(\n",
    "    ch4_preprocessed\n",
    "    .reset_index() # convert DateTimeIndex to columns\n",
    "    .rename(columns={'index': 'date', 0: 'ch4_ppb'})\n",
    "    .to_csv(output_path, index=False)\n",
    ")\n",
    "\n",
    "print(f'CH4 preprocessed data saved to:\\n{output_path}')\n",
    "print(f'Shape: {ch4_preprocessed.shape}\\nLast 5 records:')\n",
    "display(ch4_preprocessed.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95c552-5ba7-43ab-9351-9a2403b988f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
